{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1271edf2-9b47-4085-add1-d4120e476139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# raw_file_ops/move_new_files.ipynb\n",
    "# Moves new `*_part_*` seed files into raw zones (DBFS + ADLS).\n",
    "#\n",
    "# - Supports ad hoc uploads via DBFS or ADLS container root.\n",
    "# - Respects file prefixes and formats:\n",
    "#    - Patients / Encounters / Claims: DBFS\n",
    "#    - Providers / Feedback:           ADLS\n",
    "#\n",
    "# Skips any file already present at the destination.\n",
    "\n",
    "from kflow.config import raw_path, adls_raw_path\n",
    "from kflow.adls import set_sas\n",
    "\n",
    "dbu = dbutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1711b378-af8c-4065-a690-3d04e421e60f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Auth for ADLS (providers/feedback live there)\n",
    "ACCOUNT   = \"kardiaadlsdemo\"\n",
    "SAS_TOKEN = dbu.secrets.get(\"kardia\", \"adls_raw_sas\")\n",
    "set_sas(ACCOUNT, SAS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69438f51-0e7c-4434-a3aa-3cf6318b205f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Config\n",
    "# Where seed files may appear\n",
    "DBFS_UPLOADS_DIR = \"dbfs:/FileStore/tables/\"\n",
    "ADLS_UPLOADS_DIR = adls_raw_path(\"\")  # root of raw container (e.g., abfss://raw@acct/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "962e46e4-a11b-41f6-b4b8-d06ff6240b48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Map filename prefix: (raw zone path, allowed extensions)\n",
    "PREFIX_MAP = {\n",
    "    \"patients_part_\":   (raw_path(\"patients\"),    (\".csv\",)),\n",
    "    \"encounters_part_\": (raw_path(\"encounters\"),  (\".avro\",)),\n",
    "    \"claims_part_\":     (raw_path(\"claims\"),      (\".parquet\",)),\n",
    "    \"providers_part_\":  (adls_raw_path(\"providers\"), (\".tsv\", \".avro\")),\n",
    "    \"feedback_part_\":   (adls_raw_path(\"feedback\"),  (\".jsonl\",)),\n",
    "}\n",
    "\n",
    "# Directories to scan for new files\n",
    "SCAN_DIRS = [DBFS_UPLOADS_DIR, ADLS_UPLOADS_DIR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df00d3e-e978-4fb6-8f54-ac122f1968bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Helpers\n",
    "_join = lambda d, f: d.rstrip(\"/\") + \"/\" + f\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    \"\"\"Create directory if needed. For ABFSS, fallback to zero-byte _KEEP marker.\"\"\"\n",
    "    try:\n",
    "        dbu.fs.mkdirs(path)\n",
    "    except Exception:\n",
    "        try:\n",
    "            dbu.fs.put(_join(path, \"_KEEP\"), \"\", overwrite=False)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def existing_names(path: str):\n",
    "    try:\n",
    "        return {f.name for f in dbu.fs.ls(path)}\n",
    "    except Exception:\n",
    "        return set()\n",
    "\n",
    "def iter_files(path: str):\n",
    "    \"\"\"Recursively yield file Info objects under `path`.\"\"\"\n",
    "    try:\n",
    "        entries = dbu.fs.ls(path)\n",
    "    except Exception:\n",
    "        return\n",
    "    for e in entries:\n",
    "        if e.name.endswith(\"/\"):\n",
    "            yield from iter_files(e.path)\n",
    "        else:\n",
    "            yield e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c454885-e22b-49ca-a679-e8b87c9caaff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Execution\n",
    "moved = skipped = 0\n",
    "moved_files, skipped_files = [], []\n",
    "\n",
    "# Ensure destination folders exist & cache their contents\n",
    "for dest, _exts in PREFIX_MAP.values():\n",
    "    ensure_dir(dest)\n",
    "dest_cache = {dest: existing_names(dest) for dest, _ in PREFIX_MAP.values()}\n",
    "\n",
    "for scan_dir in SCAN_DIRS:\n",
    "    for fi in iter_files(scan_dir):\n",
    "        fname = fi.name\n",
    "        low   = fname.lower()\n",
    "\n",
    "        # find target dir\n",
    "        target = None\n",
    "        for prefix, (dest, exts) in PREFIX_MAP.items():\n",
    "            if low.startswith(prefix) and low.endswith(exts):\n",
    "                target = dest\n",
    "                break\n",
    "        if not target:\n",
    "            continue  # unrecognized file\n",
    "\n",
    "        if fname in dest_cache[target]:\n",
    "            skipped += 1\n",
    "            skipped_files.append(fname)\n",
    "            print(f\"Skipped (exists): {fname}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            dbu.fs.cp(fi.path, _join(target, fname))\n",
    "            dest_cache[target].add(fname)\n",
    "            moved += 1\n",
    "            moved_files.append(fname)\n",
    "            print(f\"Copied: {fname} â†’ {target}\")\n",
    "        except Exception as e:\n",
    "            print(f\"FAILED to copy {fname}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6c1b918-cbfb-4d23-9cd6-11f202da53a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Summary\n",
    "print(f\"Move complete. Moved: {moved:,}, Skipped: {skipped:,}\")\n",
    "\n",
    "if moved_files:\n",
    "    print(\"Moved files:\\n  \" + \"\\n  \".join(moved_files))\n",
    "\n",
    "if skipped_files:\n",
    "    print(\"Skipped files:\\n  \" + \"\\n  \".join(skipped_files))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "move_new_files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
