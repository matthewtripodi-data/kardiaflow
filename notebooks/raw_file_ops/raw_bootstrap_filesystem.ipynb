{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# raw_bootstrap_filesystem.ipynb\n",
    "# Bootstrap of raw zones (DBFS + ADLS).\n",
    "# - Patients/Encounters/Claims -> DBFS\n",
    "# - Providers/Feedback         -> ADLS `raw` container\n",
    "# Re-running this notebook will NOT duplicate files.\n",
    "\n",
    "from kflow.config import (\n",
    "    raw_path, adls_raw_path,\n",
    "    BRONZE_DB, SILVER_DB, GOLD_DB, VALIDATION_DB\n",
    ")\n",
    "from kflow.adls import set_sas\n",
    "\n",
    "dbu = dbutils"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Spark / Delta defaults\n",
    "spark.conf.set(\"spark.databricks.delta.properties.defaults.autoOptimize.optimizeWrite\", \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.properties.defaults.autoOptimize.autoCompact\",  \"true\")\n",
    "spark.conf.set(\"spark.databricks.delta.properties.defaults.enableChangeDataFeed\",        \"true\")\n",
    "spark.conf.set(\"spark.sql.variable.substitute\", \"true\")\n",
    "spark.conf.set(\"kflow.rapid_fire.threshold\", 5)\n",
    "spark.conf.set(\"kflow.claims.hourly.time_col\", \"_ingest_ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37f6e142-b249-4c95-a863-cf098d5a6d15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Databases\n",
    "DBS = [BRONZE_DB, SILVER_DB, GOLD_DB, VALIDATION_DB]\n",
    "DB_PROPS = \"\"\"\n",
    "  'delta.autoOptimize.optimizeWrite'='true',\n",
    "  'delta.autoOptimize.autoCompact' ='true'\n",
    "\"\"\"\n",
    "for db in DBS:\n",
    "    spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db}\")\n",
    "    spark.sql(f\"ALTER DATABASE {db} SET DBPROPERTIES ({DB_PROPS})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4253f732-118b-4ab2-a0ba-0abcc64f14f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. ADLS auth (for providers & feedback)\n",
    "ADLS_ACCOUNT = \"kardiaadlsdemo\"\n",
    "SAS_TOKEN    = dbu.secrets.get(\"kardia\", \"adls_raw_sas\")\n",
    "set_sas(ADLS_ACCOUNT, SAS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1bb70aa-01f1-4c4f-b47c-378ac1a7705c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Seed raw dirs with first sample files (run once per env)\n",
    "UPLOADS_DIR = \"dbfs:/FileStore/tables/\"  # where seed files are uploaded\n",
    "\n",
    "# dataset -> (filename, destination_dir)\n",
    "INITIAL_FILES = {\n",
    "    # DBFS-backed\n",
    "    \"patients\":   (\"patients_part_1.csv\",    raw_path(\"patients\")),\n",
    "    \"encounters\": (\"encounters_part_1.avro\", raw_path(\"encounters\")),\n",
    "    \"claims\":     (\"claims_part_1.parquet\",  raw_path(\"claims\")),\n",
    "    # ADLS-backed\n",
    "    \"providers\":  (\"providers_part_1.tsv\",   adls_raw_path(\"providers\")),\n",
    "    \"feedback\":   (\"feedback_part_1.jsonl\",  adls_raw_path(\"feedback\")),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e6de7eb-a31f-43df-b3d2-560ff2c9eaed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Helpers\n",
    "def _join(dir_path: str, fname: str) -> str:\n",
    "    return dir_path.rstrip(\"/\") + \"/\" + fname\n",
    "\n",
    "def list_names(path: str):\n",
    "    \"\"\"Return the file names in `path`. Empty list if path is missing/forbidden.\"\"\"\n",
    "    try:\n",
    "        return [f.name for f in dbu.fs.ls(path)]\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "def ensure_dir(path: str):\n",
    "    \"\"\"Create folder if needed. For ABFSS, fallback to a zero-byte _KEEP file.\"\"\"\n",
    "    try:\n",
    "        dbu.fs.mkdirs(path)\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "    marker = _join(path, \"_KEEP\")\n",
    "    try:\n",
    "        dbu.fs.put(marker, \"\", overwrite=False)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def bootstrap(upload_dir: str, files: dict):\n",
    "    # 1. Ensure all destination dirs exist\n",
    "    for _, dest_dir in files.values():\n",
    "        ensure_dir(dest_dir)\n",
    "\n",
    "    # 2. Snapshot of what's already uploaded & what's already in each dest\n",
    "    uploaded = set(list_names(upload_dir))\n",
    "    dest_cache = {dest: set(list_names(dest)) for _, dest in files.values()}\n",
    "\n",
    "    # 3. Copy only if missing\n",
    "    for ds, (fname, dest_dir) in files.items():\n",
    "        if fname not in uploaded:\n",
    "            print(f\"[{ds}] Skipped – {fname} not in {upload_dir}\")\n",
    "            continue\n",
    "        if fname in dest_cache[dest_dir]:\n",
    "            print(f\"[{ds}] Skipped (exists): {_join(dest_dir, fname)}\")\n",
    "            continue\n",
    "        src = _join(upload_dir, fname)\n",
    "        dst = _join(dest_dir, fname)\n",
    "        try:\n",
    "            dbu.fs.cp(src, dst)\n",
    "            print(f\"[{ds}] Copied: {fname} → {dst}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{ds}] FAILED to copy {fname} → {dest_dir}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32136264-e314-45c7-99ad-d14ef778531e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 6. Execute\n",
    "bootstrap(UPLOADS_DIR, INITIAL_FILES)\n",
    "print(\"Bootstrap complete\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bootstrap_raw",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
