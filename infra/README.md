# Kardiaflow Infrastructure Deployment Guide

This folder contains the infrastructure-as-code (IaC) scripts for deploying and
tearing down the minimal Kardiaflow development environment in Azure using Bicep
and the Azure CLI.


## What It Deploys

KardiaFlow can be deployed in two modes depending on your Databricks workspace tier:

| Mode      | Bicep File                | Workspace Tier | Notes                                  |
|-----------|---------------------------|----------------|----------------------------------------|
| Standard  | `deploy_standard.bicep`   | Databricks Standard SKU | Minimal cost; no Unity Catalog features |
| Premium   | `deploy_premium.bicep`    | Databricks Premium SKU  | Enables Unity Catalog, dashboards, etc. |

---

### Resource Summary

| Resource Group                     | Resources Created                                                                                                                | Notes                                                                                     | Cost Guidance                                                                                                   |
|-----------------------------------|----------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------|
| **kardiaâ€‘rgâ€‘dev**                 | â€¢ `kardiaâ€‘dbx` (Databricks workspace)<br>â€¢ `kardiaadlsdemo` (ADLS Gen2 account, `raw` container)                                 | Control objects defined in Bicep script                                                   | â€¢ Workspace is control-plane only (no cost while clusters are off).<br>â€¢ Storage billed by usage (LRS hot tier)<br>â€¢ Premium DBU rate may double job run costs (e.g., +$0.30â€“$0.90/day)    |
| **kardiaâ€‘dbxâ€‘managed** (autogenerated) | â€¢ `dbmanagedidentity`<br>â€¢ `dbstorageâ€¦`<br>â€¢ `workersâ€‘vnet`<br>â€¢ `workersâ€‘sg`<br>â€¢ `unity-catalog-access-connector` <br><small>(Premium only)</small> | Auto-provisioned by Databricks when deploying a Premium workspace                         | â€¢ All resources are free except DBFS (`dbstorage`, usually < 5 GB).<br>â€¢ Access Connector is free               |
| **NetworkWatcherRG** (autogenerated)   | â€¢ `NetworkWatcher_<region>`                                                                                                     | Created by Azure when a VNet is created in a region                                       | Free                                                                                                            |

---

> Use `deploy_premium.bicep` **only when** Unity Catalog or dashboard features are required. The standard deployment avoids those capabilities for lower cost and simplicity.


## Deploy Instructions

Run these from your local terminal in the project root. Make sure you're logged into the correct Azure subscription.

**1. Load environment variables from .env**

```bash
source infra/.env
```

---

**2. Create the Azure resource group**

```bash
az group create --name "$RG" --location eastus
```

---

**3.  Deploy infrastructure with Bicep (Databricks + ADLS)**

```bash
# Option A â€“ Standard (default, cheaper)
az deployment group create \
  --resource-group "$RG" \
  --template-file infra/bicep/deploy_standard.bicep \
  --name "$DEPLOY"
```

```bash
# Option B â€“ Premium (if needed for dashboards or Unity Catalog)
az deployment group create \
  --resource-group "$RG" \
  --template-file infra/bicep/deploy_premium.bicep \
  --name "$DEPLOY"
```

---

**4. Generate a Databricks Personal Access Token (PAT)**

(Databricks UI â†’ Settings â†’ Developer â†’ Generate New Token)

---

**5. Add your PAT to.env as `DATABRICKS_PAT=...`**

---

**6. Run gen_sas.sh to auto-generate and store the ADLS SAS token in Databricks**

```bash
infra/deploy/gen_sas.sh
```

---

**7. Upload the wheel to Workspace Files (stable alias path):**

This builds the wheel from your local pyproject.toml and uploads it to a stable workspace location (/Workspace/Shared/libs/kflow-latest.whl), which will never change across versions.

```bash
python -m pip install --upgrade build
python -m build

# Create the folder once; harmless if it already exists
databricks workspace mkdirs "/Shared/libs"

# Overwrite the same alias path each time
databricks workspace import --format AUTO \
  --file dist/*.whl \
  "/Shared/libs/kflow-latest.whl" --overwrite
```

You now have a canonical install path:

> /Workspace/Shared/libs/kflow-latest.whl

---

**8. Attach the wheel to each task (one-time only)**

Add this to each job task definition:

```bash
"libraries": [
  { "whl": "/Workspace/Shared/libs/kflow-latest.whl" }
]
```

> ðŸ’¡ This is required because shared job clusters ignore cluster-level libraries â€” task-level libraries are the only reliable method unless you're using Unity Catalog or workspace init scripts (which are more complex to manage).

**9. You can reset the job with the following command:**

```bash
databricks jobs reset --json @pipelines/reset_kardiaflow_full_run_batch.json
```

NOTE:

When you cut a new wheel version, just run:

```bash
python -m build
databricks workspace import --format AUTO \
  --file dist/*.whl \
  "/Shared/libs/kflow-latest.whl" --overwrite
```
- No JSON edits
- No task edits
- No cluster edits
- No init script required

---

**10. Tear down all provisioned resources safely**

```bash
./infra/deploy/teardown.sh
```

The teardown script script will:

- Delete the Databricks workspace (which deletes the managed RG too)
- Delete the main resource group (kardia-rg-dev)
- Print a confirmation message
- Resources will disappear over the next 2â€“5 minutes.

---

### Dry-Run Deployment

To preview what the deployment will do without actually creating resources:

```bash
az deployment group what-if \
  --resource-group "$RG" \
  --template-file infra/bicep/deploy.bicep \
  --name "$DEPLOY"
```