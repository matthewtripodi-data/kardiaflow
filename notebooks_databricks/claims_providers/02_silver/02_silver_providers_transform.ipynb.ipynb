{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bcd3903-19d1-4296-95d3-fa9e8d6ccbd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 02_silver_providers_dim.ipynb\n",
    "# SOURCE:  kardia_bronze.bronze_providers\n",
    "# OUTPUT:  kardia_silver.silver_providers_dim  (Type‑2 history)\n",
    "# TRIGGER: Full‑snapshot merge; fine for demo‑scale data.\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql  import functions as F\n",
    "\n",
    "# Table paths\n",
    "BRONZE_TABLE = \"kardia_bronze.bronze_providers\"\n",
    "DIM_TABLE    = \"kardia_silver.silver_providers_dim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0596a7c-fa5b-4d8f-a25f-5806ac894047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Ensure Silver DB and dimension table exist\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS kardia_silver\")\n",
    "\n",
    "if not spark.catalog.tableExists(DIM_TABLE):\n",
    "    # Create empty dim table with correct schema\n",
    "    empty_df = spark.table(BRONZE_TABLE).limit(0) \\\n",
    "                    .withColumn(\"eff_start_ts\", F.current_timestamp()) \\\n",
    "                    .withColumn(\"eff_end_ts\",   F.lit(None).cast(\"timestamp\")) \\\n",
    "                    .withColumn(\"is_current\",   F.lit(True))\n",
    "    empty_df.write.format(\"delta\").saveAsTable(DIM_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec8588c-0ecd-4d4e-ac6a-8fe0719a6cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Build (current) snapshot from Bronze\n",
    "src_df = (\n",
    "    spark.table(BRONZE_TABLE)\n",
    "         .withColumn(\"eff_start_ts\", F.current_timestamp())\n",
    "         .withColumn(\"eff_end_ts\",   F.lit(None).cast(\"timestamp\"))\n",
    "         .withColumn(\"is_current\",   F.lit(True))\n",
    ")\n",
    "\n",
    "# NOTE:  Re‑runs of provider dim create extra versions. Only current timestamp as eff_start_ts.\n",
    "# If you re‑run the job minutes later with no changes, all rows will be re‑inserted (new eff_start_ts)\n",
    "# and previous versions closed. That inflates history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a75704-6abc-451c-8d6d-5bb81f2453d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. SCD‑2 merge: close changed rows, insert new\n",
    "dim = DeltaTable.forName(spark, DIM_TABLE)\n",
    "\n",
    "(\n",
    "    dim.alias(\"t\")\n",
    "       .merge(src_df.alias(\"s\"), \"t.ProviderID = s.ProviderID AND t.is_current\")\n",
    "       .whenMatchedUpdate(\n",
    "           condition=(\n",
    "            \"t.ProviderSpecialty <> s.ProviderSpecialty OR \"\n",
    "            \"t.ProviderLocation  <> s.ProviderLocation\"\n",
    "        ),\n",
    "        set={\n",
    "            \"eff_end_ts\": F.current_timestamp(),\n",
    "            \"is_current\": F.lit(False)\n",
    "        }\n",
    ")\n",
    "       .whenNotMatchedInsertAll()\n",
    "       .execute()\n",
    ")\n",
    "\n",
    "print(\"Providers dimension refreshed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_providers_transform.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
