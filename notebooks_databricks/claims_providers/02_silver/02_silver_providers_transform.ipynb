{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4bcd3903-19d1-4296-95d3-fa9e8d6ccbd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 02_silver_providers_dim.py\n",
    "# SOURCE : kardia_bronze.bronze_providers  (Bronze appends snapshots; _ingest_ts present; CDF available but unused here)\n",
    "# OUTPUT : kardia_silver.silver_providers_dim  (SCD‑2 w/ eff_start_ts, eff_end_ts, is_current)\n",
    "# PATTERN: Simple batch full‑snapshot compare (demo scale). Phase 1 close changed rows; Phase 2 insert new/changed.\n",
    "# NOTE   : eff_start_ts taken from Bronze _ingest_ts (fallback now()) to avoid artificial history churn.\n",
    "\n",
    "from pyspark.sql import functions as F, Window\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Table paths\n",
    "BRONZE_TABLE = \"kardia_bronze.bronze_providers\"\n",
    "SILVER_DB    = \"kardia_silver\"\n",
    "DIM_TABLE    = f\"{SILVER_DB}.silver_providers_dim\"\n",
    "\n",
    "# Columns that trigger a new SCD2 version when values differ (null-safe).\n",
    "CHANGE_COLS = [\"ProviderSpecialty\", \"ProviderLocation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0596a7c-fa5b-4d8f-a25f-5806ac894047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Ensure DB + Dim table exist\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {SILVER_DB}\")\n",
    "\n",
    "if not spark.catalog.tableExists(DIM_TABLE):\n",
    "    base0 = spark.table(BRONZE_TABLE).limit(0)\n",
    "    dim0  = (base0\n",
    "             .withColumn(\"eff_start_ts\", F.current_timestamp())\n",
    "             .withColumn(\"eff_end_ts\",   F.lit(None).cast(\"timestamp\"))\n",
    "             .withColumn(\"is_current\",   F.lit(True)))\n",
    "    dim0.write.format(\"delta\").saveAsTable(DIM_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ec8588c-0ecd-4d4e-ac6a-8fe0719a6cd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Latest Bronze snapshot per ProviderID\n",
    "#    (Bronze appends each seed; pick max _ingest_ts per key.)\n",
    "bronze_df  = spark.table(BRONZE_TABLE)\n",
    "has_ingest = \"_ingest_ts\" in bronze_df.columns\n",
    "\n",
    "if has_ingest:\n",
    "    w = Window.partitionBy(\"ProviderID\").orderBy(F.col(\"_ingest_ts\").desc())\n",
    "    latest_src = (bronze_df\n",
    "                  .withColumn(\"_rn\", F.row_number().over(w))\n",
    "                  .filter(\"_rn = 1\")\n",
    "                  .drop(\"_rn\")\n",
    "                  .withColumn(\"eff_start_ts\", F.col(\"_ingest_ts\").cast(\"timestamp\")))\n",
    "else:\n",
    "    latest_src = bronze_df.withColumn(\"eff_start_ts\", F.current_timestamp())\n",
    "\n",
    "latest_src = (latest_src\n",
    "              .withColumn(\"eff_end_ts\", F.lit(None).cast(\"timestamp\"))\n",
    "              .withColumn(\"is_current\", F.lit(True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11a75704-6abc-451c-8d6d-5bb81f2453d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Close changed rows (null-safe diffs)\n",
    "dim = DeltaTable.forName(spark, DIM_TABLE)\n",
    "\n",
    "change_pred = (\n",
    "    \"NOT (t.ProviderSpecialty <=> s.ProviderSpecialty) OR \"\n",
    "    \"NOT (t.ProviderLocation  <=> s.ProviderLocation)\"\n",
    ")\n",
    "\n",
    "(dim.alias(\"t\")\n",
    "    .merge(\n",
    "        latest_src.alias(\"s\"),\n",
    "        \"t.ProviderID = s.ProviderID AND t.is_current = true\"\n",
    "    )\n",
    "    .whenMatchedUpdate(\n",
    "        condition=change_pred,\n",
    "        set={\n",
    "            \"eff_end_ts\": F.col(\"s.eff_start_ts\"),  # close at start of new version\n",
    "            \"is_current\": F.lit(False)\n",
    "        }\n",
    "    )\n",
    "    .execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "503c5e7f-463b-4980-b625-c124b7848791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Insert new *and* changed rows (no open current match left)\n",
    "(dim.alias(\"t\")\n",
    "    .merge(\n",
    "        latest_src.alias(\"s\"),\n",
    "        \"t.ProviderID = s.ProviderID AND t.is_current = true\"\n",
    "    )\n",
    "    .whenNotMatchedInsertAll()\n",
    "    .execute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6385ff43-1c0a-424d-b949-212a04df1fd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Validate\n",
    "print(f\"Providers dimension refreshed. Rows: {spark.table(DIM_TABLE).count()}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_providers_transform",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
